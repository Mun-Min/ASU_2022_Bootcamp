{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f3be44",
   "metadata": {},
   "source": [
    "# Transfer Learning: Model Homes\n",
    "\n",
    "## Background \n",
    "\n",
    "One service that some real estate technology (or \"proptech\") companies like [Redfin](https://www.redfin.com/what-is-my-home-worth) or [Zillow](https://www.zillow.com/sellerlanding/pricingtool/) offer are estimates of property value, for just about every property in the United States. \n",
    "\n",
    "But how do they know what any given property is worth? The answer is that they apply ready-made models, feeding the individual characteristics of any house into that model, with the resulting output being the model's prediction of what that home is currently worth.\n",
    "\n",
    "Just like those firms, in this activity, your job is to load a ready-made model built from modeling many thousands of different home prices in Los Angeles County, California. You'll then apply this model to the smaller market for homes in San Diego County, California. Because these markets are similar, yet somewhat different, you'll also apply what you know about transfer learning to make adjustments to your pre-loaded model so that it can be better tailored to the specifics of homes in San Diego County.\n",
    "    \n",
    "## Instructions\n",
    "\n",
    "1. Load the model (`los_angeles_model.json`) and its weights (`los_angeles_model.h5`) from the Resources folder.\n",
    "\n",
    "2. Use the `layers` attribute or `summary` function to count how many layers there are.\n",
    "\n",
    "3. Read in the San Diego County data (`san_diego.csv`, then `train_test_split` that data.\n",
    "    >Note: the `y` variable should be `pricePerSquareFoot`, and the `X` data should include `livingArea`,`bathrooms`,`bedrooms`,and `garageSpaces`.\n",
    "\n",
    "4. Freeze the existing layers of the loaded model. Verify all layers are frozen by printing the `summary` of the model's architecture.\n",
    "\n",
    "5. Create a new network which is an exact copy of this loaded model, except that the top layer of the original model is removed.\n",
    "\n",
    "6. Replace those removed layers with one or two new layers (including the final output layer). Ensure that these new trainable layers are added by using the `summary` function on this revised model. \n",
    "\n",
    "7. Finallly, `compile` and `fit` this newly revised model to the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "566da2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf641ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# Load the model (`los_angeles_model.json`) and its weights (`los_angeles_model.h5`) from the Resources folder.\n",
    "\n",
    "# load json and create model\n",
    "with open(\"../Resources/los_angeles_model.json\", \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "loaded_model = model_from_json(model_json)\n",
    "\n",
    "# load weights into new model\n",
    "file_path = \"../Resources/los_angeles_model.h5\"\n",
    "loaded_model.load_weights(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68027a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.dense.Dense at 0x1cd6e5bb808>,\n",
       " <keras.layers.core.dense.Dense at 0x1cd6e638508>,\n",
       " <keras.layers.regularization.dropout.Dropout at 0x1cd6e680e48>,\n",
       " <keras.layers.core.dense.Dense at 0x1cd6e691a48>,\n",
       " <keras.layers.core.dense.Dense at 0x1cd6e6bc508>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the `layers` attribute or `summary` function to count how many layers there are\n",
    "loaded_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37b6a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the San Diego County data\n",
    "df = pd.read_csv(\n",
    "    Path('../Resources/san_diego.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b423ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stateId</th>\n",
       "      <th>countyId</th>\n",
       "      <th>cityId</th>\n",
       "      <th>country</th>\n",
       "      <th>datePostedString</th>\n",
       "      <th>is_bankOwned</th>\n",
       "      <th>is_forAuction</th>\n",
       "      <th>event</th>\n",
       "      <th>time</th>\n",
       "      <th>...</th>\n",
       "      <th>parking</th>\n",
       "      <th>garageSpaces</th>\n",
       "      <th>hasGarage</th>\n",
       "      <th>levels</th>\n",
       "      <th>pool</th>\n",
       "      <th>spa</th>\n",
       "      <th>isNewConstruction</th>\n",
       "      <th>hasPetsAllowed</th>\n",
       "      <th>homeType</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92037-16835229</td>\n",
       "      <td>9</td>\n",
       "      <td>1393</td>\n",
       "      <td>54296</td>\n",
       "      <td>USA</td>\n",
       "      <td>7/13/21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Listed for sale</td>\n",
       "      <td>1.626130e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Two</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CONDO</td>\n",
       "      <td>San Diego County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  stateId  countyId  cityId country datePostedString  \\\n",
       "0  92037-16835229        9      1393   54296     USA          7/13/21   \n",
       "\n",
       "   is_bankOwned  is_forAuction            event          time  ...  parking  \\\n",
       "0             0              0  Listed for sale  1.626130e+12  ...        1   \n",
       "\n",
       "   garageSpaces hasGarage levels  pool spa  isNewConstruction  hasPetsAllowed  \\\n",
       "0             2         1    Two     0   1                  0               0   \n",
       "\n",
       "   homeType            county  \n",
       "0     CONDO  San Diego County  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a32211d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The `y` variable should be `pricePerSquareFoot` \n",
    "#The `X` data should include `livingArea`,`bathrooms`,`bedrooms`,and `garageSpaces`\n",
    "y = df['pricePerSquareFoot']\n",
    "X = df[['livingArea','bathrooms','bedrooms','garageSpaces']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c5f4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing windows\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Create the StandardScaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale both the training and testing data from the features dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "877722b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the existing layers of the loaded model\n",
    "for layer in loaded_model.layers[0:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31963b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 18        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6)                 0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 21        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53\n",
      "Trainable params: 4\n",
      "Non-trainable params: 49\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Verify all layers are frozen by printing the `summary` of the\n",
    "# model's architecture.\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "584d8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new network which is an exact copy of this loaded model,\n",
    "# except that the top layer of the original model is removed.\n",
    "\n",
    "transfer_model = Sequential()\n",
    "\n",
    "for layer in loaded_model.layers[:-1]: \n",
    "    transfer_model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f6db224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace those removed layers with one or two new layers\n",
    "# (including the final output layer). \n",
    "\n",
    "# Add an additional layer\n",
    "transfer_model.add(Dense(10, activation=\"relu\"))\n",
    "\n",
    "# Add the final output layer\n",
    "transfer_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a42bdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 18        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6)                 0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 21        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                40        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 51\n",
      "Non-trainable params: 49\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Ensure that these new trainable layers are added by using\n",
    "# the `summary` function on this revised model.\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b2f7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "transfer_model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9373adec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 [==============================] - 2s 5ms/step - loss: 534.6593 - accuracy: 0.0872\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 534.6174 - accuracy: 0.0872\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 534.5755 - accuracy: 0.0872\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 534.5224 - accuracy: 0.0872\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 534.4630 - accuracy: 0.0872\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 534.3989 - accuracy: 0.0872\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 534.3386 - accuracy: 0.0872\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 534.2789 - accuracy: 0.0872\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 534.2172 - accuracy: 0.0872\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 534.1507 - accuracy: 0.0804\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 534.0821 - accuracy: 0.0614\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 534.0065 - accuracy: 0.0106\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 533.9266 - accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 533.8421 - accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 533.7512 - accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 533.6575 - accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 533.5572 - accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 533.4536 - accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 533.3420 - accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 533.2307 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cd6eb36108>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "transfer_model.fit(X_train_scaled,y_train, \n",
    "                    epochs=20,\n",
    "                    batch_size=100,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c38e3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 1s - loss: 543.1595 - accuracy: 0.0000e+00 - 578ms/epoch - 41ms/step\n",
      "Loss: 543.1594848632812, Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = transfer_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "# Display the evaluation results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a7ae136a53a24601e63a177d18d4029f938b6714f24b844ae865dcffb9f6766"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
