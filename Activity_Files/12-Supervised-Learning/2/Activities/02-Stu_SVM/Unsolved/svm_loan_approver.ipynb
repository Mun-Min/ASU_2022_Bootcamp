{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Loan Approver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of classification algorithms that can be used to determine loan elgibility. Some algorithms run better than others. Build a loan approver using the SVM algorithm and compare the accuracy and performance of the SVM model with the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import style\n",
    "style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assets</th>\n",
       "      <th>liabilities</th>\n",
       "      <th>income</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.210859</td>\n",
       "      <td>0.452865</td>\n",
       "      <td>0.281367</td>\n",
       "      <td>0.628039</td>\n",
       "      <td>0.302682</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395018</td>\n",
       "      <td>0.661153</td>\n",
       "      <td>0.330622</td>\n",
       "      <td>0.638439</td>\n",
       "      <td>0.502831</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.291186</td>\n",
       "      <td>0.593432</td>\n",
       "      <td>0.438436</td>\n",
       "      <td>0.434863</td>\n",
       "      <td>0.315574</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.458640</td>\n",
       "      <td>0.576156</td>\n",
       "      <td>0.744167</td>\n",
       "      <td>0.291324</td>\n",
       "      <td>0.394891</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.463470</td>\n",
       "      <td>0.292414</td>\n",
       "      <td>0.489887</td>\n",
       "      <td>0.811384</td>\n",
       "      <td>0.566605</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     assets  liabilities    income  credit_score  mortgage   status\n",
       "0  0.210859     0.452865  0.281367      0.628039  0.302682     deny\n",
       "1  0.395018     0.661153  0.330622      0.638439  0.502831  approve\n",
       "2  0.291186     0.593432  0.438436      0.434863  0.315574  approve\n",
       "3  0.458640     0.576156  0.744167      0.291324  0.394891  approve\n",
       "4  0.463470     0.292414  0.489887      0.811384  0.566605  approve"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "# Note: The following data has been normalized between 0 and 1\n",
    "data = Path('../Resources/loans.csv')\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the Features (X) from the Target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the features from the target\n",
    "X = df.drop(columns = 'status')\n",
    "y = df.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Split our data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use the train_test_split function to create training and testing subsets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Create a SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate a linear SVM model\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto',\n",
    "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fit (train) or model using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto', kernel='linear')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>status (actual)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deny</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deny</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deny</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deny</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>approve</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deny</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>deny</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>deny</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>deny</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>deny</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>deny</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>deny</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction status (actual)\n",
       "0        deny            deny\n",
       "1        deny         approve\n",
       "2        deny         approve\n",
       "3        deny         approve\n",
       "4        deny         approve\n",
       "5     approve            deny\n",
       "6        deny            deny\n",
       "7        deny            deny\n",
       "8        deny            deny\n",
       "9        deny            deny\n",
       "10       deny         approve\n",
       "11       deny         approve\n",
       "12       deny            deny\n",
       "13       deny         approve\n",
       "14       deny         approve\n",
       "15       deny         approve\n",
       "16       deny            deny\n",
       "17       deny            deny\n",
       "18       deny         approve\n",
       "19       deny            deny\n",
       "20       deny            deny\n",
       "21       deny            deny\n",
       "22       deny         approve\n",
       "23       deny            deny\n",
       "24       deny            deny"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions using the test data \n",
    "testing_predictions = model.predict(X_test)\n",
    "training_predictions = model.predict(X_train)\n",
    "\n",
    "predictions_df = pd.DataFrame(testing_predictions)\n",
    "predictions_df.columns = ['Prediction']\n",
    "predictions_df['status (actual)'] = df['status']\n",
    "\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Score the model using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.56\n",
      "Testing Data Score: 0.4\n"
     ]
    }
   ],
   "source": [
    "# Score the accuracy and print results\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_accuracy = accuracy_score(y_train, training_predictions)\n",
    "test_accuracy = accuracy_score(y_test, testing_predictions)\n",
    "\n",
    "print(f\"Training Data Score: {train_accuracy}\")\n",
    "print(f\"Testing Data Score: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 14]\n",
      " [ 1 10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# testing data confusion matrix \n",
    "testing_matrix = confusion_matrix(y_test, testing_predictions)\n",
    "print(testing_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     approve       0.00      0.00      0.00        14\n",
      "        deny       0.42      0.91      0.57        11\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.21      0.45      0.29        25\n",
      "weighted avg       0.18      0.40      0.25        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate the classification report for the test data.\n",
    "testing_report = classification_report(y_test, testing_predictions)\n",
    "print(testing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     approve       0.00      0.00      0.00        33\n",
      "        deny       0.56      1.00      0.72        42\n",
      "\n",
      "    accuracy                           0.56        75\n",
      "   macro avg       0.28      0.50      0.36        75\n",
      "weighted avg       0.31      0.56      0.40        75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minha\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\minha\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\minha\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "training_report = classification_report(y_train, training_predictions)\n",
    "print(training_report)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.7.13 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "6a7ae136a53a24601e63a177d18d4029f938b6714f24b844ae865dcffb9f6766"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
